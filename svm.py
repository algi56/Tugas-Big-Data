# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18x1tS1KkR2XuB1LHRgB8ZAd30sdLARTz

**Mengimport library yang akan digunakan**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt # for data visualization
import seaborn as sns # for statistical data visualization
# %matplotlib inline

import os
for dirname, _, filenames in os.walk('/content/drive/MyDrive/Colab Notebooks/SVM'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import warnings

warnings.filterwarnings('ignore')

"""**Menginput data yang akan digunakan**


"""

data = '/content/drive/MyDrive/Colab Notebooks/SVM/pulsar_stars.csv'

df = pd.read_csv(data)

"""**EXploratory Data Analysis**"""

df.shape

"""untuk melihat dimensi dari set data

pada set data terdapat 17898 sample dan 9 variabel
"""

df.head()

"""Menampilkan data dalam bentuk tabel"""

col_names = df.columns

col_names

"""Menampilkan nama kolom dari tabel data"""

df.columns = df.columns.str.strip()

df.columns

"""**Mengubah nama Kolom**"""

df.columns = ['IP Mean', 'IP Sd', 'IP Kurtosis', 'IP Skewness',
              'DM-SNR Mean', 'DM-SNR Sd', 'DM-SNR Kurtosis', 'DM-SNR Skewness', 'target_class']

df.columns

"""**Memeriksa distribusi "target_class"**"""

df['target_class'].value_counts()

"""bagian distribusi untuk persentase "target_class"
"""

df['target_class'].value_counts()/np.float64(len(df))

"""Persentase dari "target_class" pada label 0 dan 1

**Info ringkasan dari set data**
"""

df.info()

"""**Memeriksa nilai yang hilang dalam semua variabel**"""

df.isnull().sum()

"""Pada hasil cek nilai hilang pada variabel, tidak ditemukan nilai yang hilang

**Melihat statistik ringkasan dalam variabel numerik**

untuk melihat outlaier dalam variabel
"""

round(df.describe(),2)

"""Jika dilihat lebih rinci lagi, dapat diasumsikan pada variabel mengandung outlier

**visualisasi dari outlier pada variabel**
"""

plt.figure(figsize=(24,20))
plt.subplot(4, 2, 1)
fig = df.boxplot(column='IP Mean')
fig.set_title('')
fig.set_ylabel('IP Mean')
plt.subplot(4, 2, 2)
fig = df.boxplot(column='IP Sd')
fig.set_title('')
fig.set_ylabel('IP Sd')
plt.subplot(4, 2, 3)
fig = df.boxplot(column='IP Kurtosis')
fig.set_title('')
fig.set_ylabel('IP Kurtosis')
plt.subplot(4, 2, 4)
fig = df.boxplot(column='IP Skewness')
fig.set_title('')
fig.set_ylabel('IP Skewness')
plt.subplot(4, 2, 5)
fig = df.boxplot(column='DM-SNR Mean')
fig.set_title('')
fig.set_ylabel('DM-SNR Mean')
plt.subplot(4, 2, 6)
fig = df.boxplot(column='DM-SNR Sd')
fig.set_title('')
fig.set_ylabel('DM-SNR Sd')
plt.subplot(4, 2, 7)
fig = df.boxplot(column='DM-SNR Kurtosis')
fig.set_title('')
fig.set_ylabel('DM-SNR Kurtosis')
plt.subplot(4, 2, 8)
fig = df.boxplot(column='DM-SNR Skewness')
fig.set_title('')
fig.set_ylabel('DM-SNR Skewness')

"""**Menangani outlier**

untuk menangani outlier dapat menggunakan SVM, yaitu hard-margin variant of SVM dan soft-margin variant of SVM

* Pada Hard-margin varian, SVM tidak menangani outlier. Tetapi Dalam hal ini, kita ingin mencari hyperplane dengan margin maksimum sehingga setiap titik pelatihan diklasifikasikan dengan benar dengan margin minimal 1. Teknik ini tidak menangani outlier dengan baik.

* Pada Soft-margin variant, Dalam hal ini, kita mungkin memiliki beberapa poin yang salah diklasifikasikan atau diklasifikasikan dengan margin kurang dari 1. Namun untuk setiap poin tersebut, kita harus membayar penalti dalam bentuk parameter C, yang mengontrol outlier. C yang rendah berarti kita memperbolehkan lebih banyak outlier dan C yang tinggi berarti lebih sedikit outlier.


Karena pada set data mengandung outlier, maka nilai C harus tinggi saat train model.

**Visualisasi plot histogram**

untuk cek distribusi
"""

plt.figure(figsize=(24,20))

plt.subplot(4, 2, 1)
fig = df['IP Mean'].hist(bins=20)
fig.set_xlabel('IP Mean')
fig.set_ylabel('Number of pulsar stars')

plt.subplot(4, 2, 2)
fig = df['IP Sd'].hist(bins=20)
fig.set_xlabel('IP Sd')
fig.set_ylabel('Number of pulsar stars')

plt.subplot(4, 2, 3)
fig = df['IP Kurtosis'].hist(bins=20)
fig.set_xlabel('IP Kurtosis')
fig.set_ylabel('Number of pulsar stars')

plt.subplot(4, 2, 4)
fig = df['IP Skewness'].hist(bins=20)
fig.set_xlabel('IP Skewness')
fig.set_ylabel('Number of pulsar stars')

plt.subplot(4, 2, 5)
fig = df['DM-SNR Mean'].hist(bins=20)
fig.set_xlabel('DM-SNR Mean')
fig.set_ylabel('Number of pulsar stars')

plt.subplot(4, 2, 6)
fig = df['DM-SNR Sd'].hist(bins=20)
fig.set_xlabel('DM-SNR Sd')
fig.set_ylabel('Number of pulsar stars')

plt.subplot(4, 2, 7)
fig = df['DM-SNR Kurtosis'].hist(bins=20)
fig.set_xlabel('DM-SNR Kurtosis')
fig.set_ylabel('Number of pulsar stars')

plt.subplot(4, 2, 8)
fig = df['DM-SNR Skewness'].hist(bins=20)
fig.set_xlabel('DM-SNR Skewness')
fig.set_ylabel('Number of pulsar stars')

"""Dari hasil plot, 8 variabel kontinu mengindikasikan distribusi miring

**deklarasi Featur Vector dan targer variable**
"""

X = df.drop(['target_class'], axis=1)

y = df['target_class']

"""**Membagi data menjadi X dan Y, menjadi training dan testing set**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""**memeriksa bentuk X_train dan X_test**"""

X_train.shape, X_test.shape

"""**Feature Penskalaan**"""

cols = X_train.columns
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_train = pd.DataFrame(X_train, columns=[cols])
X_test = pd.DataFrame(X_test, columns=[cols])
X_train.describe()

"""set data X_train siap untuk dimasukan dalam Logistic Regression Classifier

**Menjalankan SVM dengan Default Hyperparameters**

Default Hyperparameter berarti nilai C=1, kerner=rbf, dan nilai gamma=auto diantara parameter lain
"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
svc=SVC()
svc.fit(X_train,y_train)
y_pred=svc.predict(X_test)

print('Nilai dari Model accuracy dengan default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""**Menjalankan classifier dengan kernel=rbf dan C=100**"""

svc=SVC(C=100.0)
svc.fit(X_train,y_train)
y_pred=svc.predict(X_test)

print('Nilai dari Model accuracy dengan kernel=rbf dan C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""**Menjalankan classifier dengan kernel=rbf dan C=500**"""

svc=SVC(C=500.0)
svc.fit(X_train,y_train)
y_pred=svc.predict(X_test)

print('Nilai dari Model accuracy dengan kernel=rbf dan C=500.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""**Menjalankan classifier dengan Linear kernel**"""

linear_svc=SVC(kernel='linear', C=1.0)
linear_svc.fit(X_train,y_train)
y_pred_test=linear_svc.predict(X_test)

print('Nilai dari Model accuracy dengan linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))

"""**Menjalankan classifier dengan Linear kernel dan C=100**"""

linear_svc100=SVC(kernel='linear', C=100.0)
linear_svc100.fit(X_train, y_train)
y_pred=linear_svc100.predict(X_test)

print('Nilai dari Model accuracy dengan linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""**Menjalankan classifier dengan Linear kernel dan C=500**"""

linear_svc500=SVC(kernel='linear', C=500.0)
linear_svc500.fit(X_train, y_train)
y_pred=linear_svc500.predict(X_test)

print('Nilai dari Model accuracy linear kernel and C=500.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""Dari hasil Run classifier, dapat diperoleh nilai akurasi pada C=100 dan C=500 lebih besar dibanding C=1


Di sini, y_test adalah label kelas yang sebenarnya dan y_pred adalah label kelas yang diprediksi dalam set pengujian.

**Membandingakan akurasi Train-set dan Test-set**
"""

y_pred_train = linear_svc.predict(X_train)

y_pred_train

print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))

"""**Mengecek Overfitting atau Underfitting**"""

print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))

print('Test set score: {:.4f}'.format(linear_svc.score(X_test, y_test)))

"""Nilai akurasi Train-set adalah 0,9783 sedangkan akurasi Test-set menjadi 0,9830. Kedua nilai ini cukup sebanding. Jadi, tidak ada pertanyaan tentang overfitting.

**Bandingkan akurasi model dengan akurasi nol**

Jadi, akurasi model adalah 0,9832. Namun, kita tidak dapat mengatakan bahwa model kita sangat baik berdasarkan akurasi di atas. Kita harus membandingkannya dengan akurasi nol. Akurasi nol adalah akurasi yang dapat dicapai dengan selalu memprediksi kelas yang paling sering muncul.

Jadi, perlu memeriksa distribusi kelas di dalam Test-set.
"""

y_test.value_counts()

"""
Terlihat bahwa kemunculan kelas 0 yang paling sering adalah 3306. Jadi dapat menghitung akurasi nol dengan membagi 3306 dengan jumlah total kemunculan."""

null_accuracy = (3306/(3306+274))

print('Nilai Null accuracy: {0:0.4f}'. format(null_accuracy))

"""Terlihat bahwa nilai akurasi model adalah 0.9830 tetapi nilai akurasi nol adalah 0.9235. Jadi, kita dapat menyimpulkan bahwa pengklasifikasi SVM melakukan pekerjaan yang sangat baik dalam memprediksi label kelas.

**Menjalankan classifier dengan Polinimial kernel dan C=1**
"""

poly_svc=SVC(kernel='poly', C=1.0)
poly_svc.fit(X_train,y_train)
y_pred=poly_svc.predict(X_test)

print('Nilai dari Model accuracy dengan polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""**Menjalankan classifier dengan Polinomial kernel dan C=100**"""

poly_svc100=SVC(kernel='poly', C=100.0)
poly_svc100.fit(X_train, y_train)
y_pred=poly_svc100.predict(X_test)

print('Nilai dari Model accuracy dengan polynomial kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""**Menjalankan classifier dengan Sigmoid kernel dan C=1**"""

sigmoid_svc=SVC(kernel='sigmoid', C=1.0)
sigmoid_svc.fit(X_train,y_train)
y_pred=sigmoid_svc.predict(X_test)

print('Nilai dari Model accuracy dengan sigmoid kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""**Menjalankan classifier dengan Sigmoid kernel dan C=100**"""

sigmoid_svc100=SVC(kernel='sigmoid', C=100.0)
sigmoid_svc100.fit(X_train,y_train)
y_pred=sigmoid_svc100.predict(X_test)

print('Nilai dari Model accuracy dengan sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

"""Dapat kita lihat bahwa Polinomial kernel dan sogmoid kernel memiliki kinerja yang buruk pada set data

**Confusion Matrix**

Confusion matrix adalah alat untuk meringkas kinerja algoritma klasifikasi.Confusion matrix akan memberikan gambaran yang jelas tentang kinerja model klasifikasi dan jenis kesalahan yang dihasilkan oleh model tersebut. Matriks ini memberikan kita ringkasan prediksi yang benar dan salah yang dikelompokkan berdasarkan setiap kategori. Ringkasan ini direpresentasikan dalam bentuk tabel.

Ada empat jenis hasil yang mungkin terjadi saat mengevaluasi kinerja model klasifikasi :

True Positives (TP ) - True Positives terjadi ketika kita memprediksi sebuah observasi termasuk ke dalam kelas tertentu dan observasi tersebut benar-benar termasuk ke dalam kelas tersebut.

True Negatives (TN ) - True Negatives terjadi ketika kita memprediksi sebuah observasi tidak termasuk dalam kelas tertentu dan observasi tersebut sebenarnya tidak termasuk dalam kelas tersebut.

False Positives (FP ) - False Positives terjadi ketika kita memprediksi sebuah observasi termasuk ke dalam kelas tertentu, namun observasi tersebut sebenarnya tidak termasuk ke dalam kelas tersebut. Jenis kesalahan ini disebut kesalahan Tipe I.

False Negatives (FN ) - False Negatives terjadi ketika kita memprediksi sebuah observasi tidak termasuk ke dalam kelas tertentu, tetapi observasi tersebut sebenarnya termasuk ke dalam kelas tersebut. Ini adalah kesalahan yang sangat serius dan disebut kesalahan Tipe II.
"""

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred_test)
print('Confusion matrix\n\n', cm)

print('\nTrue Positives(TP) = ', cm[0,0])
print('\nTrue Negatives(TN) = ', cm[1,1])
print('\nFalse Positives(FP) = ', cm[0,1])
print('\nFalse Negatives(FN) = ', cm[1,0])

"""**Visualisasi dari Confusion Matrix**"""

cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],
                                 index=['Predict Positive:1', 'Predict Negative:0'])

sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')

"""**Classification Report**

Classification Report adalah cara lain untuk mengevaluasi kinerja model klasifikasi. Laporan ini menampilkan nilai presisi, recall, f1, dan support untuk model.
"""

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_test))